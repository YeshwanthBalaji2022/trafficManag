## âœ… Phase 0: Setup & Prep (Now)

### ğŸ¯ Goal: Prepare the dev environment and core project structure.

#### Tasks:

1. **Initialize a monorepo or two separate repos**:

   ```
   traffic-project/
   â”œâ”€â”€ frontend/  â† React app
   â””â”€â”€ backend/   â† FastAPI + SocketIO + RL training
   ```

2. **Set up tools**:

   * `Node.js`, `npm`, `Python 3.10+`, `Poetry` or `venv`
   * Install: `npx create-react-app`, `FastAPI`, `uvicorn`, `socket.io`, `Redis`, `Docker`

3. **Create basic `.env` files**:

   * Frontend: WebSocket URL
   * Backend: Redis URL, DB URL, Port

---

## ğŸŸ© Phase 1: Build a Minimal Simulation (Week 1)

### ğŸ¯ Goal: Show a basic traffic simulation with autonomous agents on a map

#### âœ… Backend (FastAPI):

* Create API `/agents/step` and `/agents/state`
* Add WebSocket endpoint `/ws` to broadcast vehicle states

#### âœ… Frontend (React + Leaflet):

* Render a map with a few agents as moving markers
* Connect to backend WebSocket and update positions live

#### âœ… Sim Engine:

* Simulate 5â€“10 agents on a fixed grid/city map
* Assign random source/destination and move step-by-step

---

## ğŸŸ§ Phase 2: Decentralized Agent Logic (Week 2)

### ğŸ¯ Goal: Let each vehicle act as a decision-making agent.

#### âœ… Backend:

* Write a basic vehicle agent class with:

  * Local state (speed, position, destination)
  * Communication stub (mock V2V)
  * Congestion detection and rerouting

* Create a central agent manager to track all vehicles

---

## ğŸŸ¨ Phase 3: Add Human Control (Week 3)

### ğŸ¯ Goal: Allow a user to manually control one of the vehicles via UI

#### âœ… Frontend:

* Let user select one vehicle to control
* Add buttons for:

  * Set destination
  * Increase/decrease speed
  * Reroute

#### âœ… Backend:

* Mark one vehicle as `"control": "user"`
* Bypass AI decisions for that vehicle
* Cache human actions into Redis/PostgreSQL

---

## ğŸŸ¦ Phase 4: RL Model Training (Week 4)

### ğŸ¯ Goal: Train and run a simple multi-agent RL model

#### âœ… Backend:

* Create a custom `TrafficEnv` with Gym interface
* Use `Stable-Baselines3` to train PPO or A2C
* Store model weights, replay logs

#### âœ… Integrate into sim:

* Load trained model for agents
* Use model output as action for each agent
* Compare performance with heuristics

---

## ğŸŸª Phase 5: Replay & Comparison Dashboard (Week 5)

### ğŸ¯ Goal: Analyze and replay previous runs

#### âœ… Frontend:

* Dropdown to select previous run
* Animate vehicle paths
* Show stats (time, reroutes, congestion)

#### âœ… Backend:

* Store each run in Redis/PostgreSQL
* Add replay API: `/runs/{id}`

---

## ğŸš€ Optional Enhancements

* Add a hybrid control mode (central coordination fallback)
* Add rewards/score for user (gamified mode)
* Integrate with **SUMO** or **CARLA** for realism

---
